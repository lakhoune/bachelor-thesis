\chapter{Evaluation}\label{cha:eval}
In this chapter, we want to evaluate how the use of a chatbot affects a community.
Specifically, we want to answer the following questions:
\begin{itemize}
    \item Does the use of chatbots increase the success awareness of the community?
    \item Does it increase collaboration between members?
    % \item Does it improve the user experience in terms of mobility?
\end{itemize}

In order to evaluate those questions, an artificial community, as described in \ref{cha:concept}, is created.  
The community is using a Slack workspace called \emph{Mensa Community} to exchange information.
The members of this community, are people , who frequent the canteen more or less regularly.
Thus, the community will consist largely of students and staff members of the university.

\section{The requirements of the community}
The first step was to find out what the requirements of the community were and what success factors are most important to them. Therefore a survey was created which asked participants to order success factors based on their relevance. 
Furthermore, users were asked to list additional factors.
A success model was then created based on the most relevant factors from the survey. The resulting success model can be seen in Listing \ref{lst:successModel}.

\begin{lstlisting}[language=XML,caption=Success Model based on requirements, label=lst:successModel]
<SuccessModel name="mensa" 
service="i5.las2peer.services.mensaService.MensaService">
    <questionnaires/>
    <dimension name="System Quality">
        <factor name="Low error rate"/>
        <factor name="Efficiency"/>
        <factor name="Fast responses"/>
    </dimension>
    <dimension name="Information Quality">
        <factor name="Reliability"/>
        <factor name="Accuracy"/>
        <factor name="Relevance"/>
    </dimension>
    <dimension name="Use">
        <factor name="Contributions"/>
        <factor name="Getting the menu"/>
        <factor name="Frequency of use"/>
    </dimension>
    <dimension name="User Satisfaction">
        <factor name="Enjoyment of use"/>
        <factor name="Number of user complaints"/>
    </dimension>
    <dimension name="Individual Impact">
        <factor name="Time to complete a task"/>
        <factor name="Time savings"/>
    </dimension>
    <dimension name="Community Impact">
    </dimension>
</SuccessModel>
\end{lstlisting}

A measure catalog with example measures was added for the community by us. The measures were created so that they would match the success factors in Listing \ref{lst:successModel}.

The evaluation was planned to be conducted in two phases.
In the first phase, we wanted to familiarize the participants with the chatbot, by allowing them to use the bot for an extended period of approximately one month. 
We also wanted to evaluate the bot's performance for providing canteen related information.
Users would have been asked to use the bot whenever they went to the canteen. 
The idea was to collect logs and reviews, which would later be used in success visualizations. 
Participants would then have been asked to fill out a questionnaire, which covered usability questions of the service, which could then in turn be included in the success model of the community.
Unfortunately, due to the Corona pandemic, the canteens were closed for most of the time. Thus, we decided not to do this first phase, but integrate it in the final evaluation.

In the final evaluation, we wanted to find out how the bot affects the success awareness of the community.
We wanted to find out if the bot is helpful for visualization of success metrics and if the bot encourages collaboration inside the community, especially for success modelling.


% % The participants will join a Slack group in which the Social Bot is deployed.
% Furthermore, there will be a group channel in which users are encouraged to exchange Mensa related topics. The Social Bot will be a part of the channel and can be used to query the canteen menu.
% Participants will also be able to make food reviews by contacting the bot in private chat. Members of the workspace could contact the bot through a private channel or add it to a public channel.

\section{Main tasks for the evaluations}

The chatbot was setup in the Slack workspace. 
We extended the success model of the community with some measures from the measure catalog. 
% We defined measures for the measure catalog which reflected the success factors of the success model.
Participants were asked to join the Slack workspace and contact the bot privately. They were asked to share their screen to be assisted in case any issues would occur. They could ask the bot at any time what its capabilities were by typing \emph{help}.
The participants were then asked to perform three main tasks.

In the first tasks, they were asked first asked to get the menu for a local canteen. This could be done with a phrase like "I want to get the menu for Mensa Academica".
They were then asked to make a review for a dish on the menu. This could be done with a phrase like "I want to write a review". The bot then asked how many stars the user would give their meal and ask them give a comment.  

In the second task, users were asked to visualize different success measures from the success model. This could be done by using a phrase like "Make a visualization". Users were told to ask the bot to list all measures and then select one of the measures from the list.

In the third task they were asked to visualize the success model. This could be done with a phrase like "Get the success model". They were then asked to update the success model by adding a measure from the measure catalog to a factor of their choice. 
This was done by first asking the bot to update the success model. The bot would then ask which dimension to update. 
The participants chose a dimension from the list. 
The bot would ask them what factor they wanted to add a measure to. 
At this stage, users could either select a factor from the list, or add a new one by providing a name. 
In the final stage, a list of measures from the measure catalog was provided and users were asked to select a number from the list. 
The bot would then add the measure to the factor and the resulting success model was returned.

\section{Evaluation results}

After performing the main tasks, participants were handed out a questionnaire.
The questionnaire covered questions about how users felt about using the bot, especially in terms of success awareness. The questionnaire was divided into six main sections. 

\subsection{Demographics}
A total of 20 participants took part in the final evaluation. Out of those 30\% had filled out the first survey about the requirements of the community. 
Most of the participants (90\%) were between 18 and 24 years old. The remaining participants were between 25 and 34 years old. Most participants were male (85\%).
The participants were asked to specify their \textbf{main} role 85\% of the participants identified as Students, 5\% identified as Researchers and 5\% as University employees. Thus all of our participants are part of our target group. Out of the 20 part 

% In order to measure the collaboration aspect, participants should be divided into groups of at least three.
% Each group should then be asked to update the success model.
% This task should be performed in the original MobSOS CCA frontend and in a group chat, which contains the bot.
\subsection{Evaluation of canteen specific tasks}  
This section covers the usability of the mensabot to get the menu of the canteen and write a review for a dish on the menu. It covered the aspects of the first main task. Figure \ref{fig:canteenPlot1} shows the results. Most participants could imagine themselves using the mensabot to get the menu and write reviews.
\input{../plots/canteen.tex} 
Participants also agreed that making reviews is useful for the community, as can be seen in Figure \ref{fig:canteenPlot2}. 
However, the awareness of the importance of making reviews was higher than the desire to contribute to the community. This could be explained by a lack of interest in the community for some participants and follows the natural structures of a community.
Some participants also noted that it would be great if the review is shown in the chat after submission and if the review could be updated at a later time.
Another participant found the procedure of adding a review a bit cumbersome, as you would have to follow a rigid number of steps, with intermediate waiting periods for the bot's answers. They suggested, that users make multiple steps at once. User could for example specify the dish, the canteen and the stars all in one message. After that, the bot could just ask for confirmation once.

On some of the first evaluations, the dish category "Vegetarisch" was not recognized as an entity, which meant that users could not write a review for vegetarian dishes. This issue was fixed on later evaluations by adding categories like "Vegetarisch" and "Klassiker" as lookups in the training data of the NLU model. As one participant also pointed out, synonyms like "classics" should also be recognized.

We were also facing an issue with one participant. They would ask for the menu of a canteen, the bot would provide a list of suggestions. The user would choose a  canteen by providing a number, but the wrong canteen was chosen in the service. We figured out that this issue was due to the fact that the selection was saved as a \texttt{Set} instead of an ordered list.
This issue has been fixed immediately after the evaluation session.

Finally, due to the current pandemic, a lot of canteens were closed. The Mensa Service does not check yet if the canteen is open before showing the canteen in the list of suggestions. This resulted in the bot failing to retrieve the menu, which caused some frustration. A possible fix for this would be to add a label to canteens which are closed. 


\input{../plots/canteen2.tex}

We conclude that the chatbot could have the potential to increase the collaboration inside the community, but does not yet fully capitalize on its potential. One possible solution, which we discussed, and which was also brought up in feedback during the evaluation sessions, is that the bot could nudge the user to make a review if they asked for the menu earlier that day.

Another way to increase contributions would be to introduce \emph{Gamification}. Users could receive certain badges when reaching defined quotas. The bot could periodically show the users contribution compared to the rest of the community to motivate them to make more reviews.

\subsection{Evaluation of visualization task}

This section covers the usability of the mensabot to get visualizations of success measures. As mentioned before, participants were asked to select a measure from the success model. The resulting visualization was then displayed in chat. As Figure \ref{fig:visualPlot1} suggests, participants mostly understood the visualizations without needing any assistance. Some participants were overwhelmed with the number of predefined measures and found that just listing the measure name is not very helpful. 

Some participants were surprised when certain measures returned a single value instead of a chart. This was due to the fact that they mistook visualizations for charts. 

\input{../plots/visualization.tex}

Overall, the visualizations seemed to be clear and intuitive to understand, even for non-technical users. Some bar-chart visualizations with long text in the y-axis resulted in the bars not being  lined up correctly with the labels. Also, if there were too many labels, the axis became overcrowded, especially in line-charts.

\input{../plots/visualization2.tex}

Figure \ref{fig:visualPlot2} shows that participants found making visualizations a useful feature. 

\input{../plots/visualization3.tex}

If we consider Figure \ref{fig:visualPlot3}, we conclude visualizations to be useful to increase the success awareness of the community.

\subsection{Evaluation of success modelling task}
Figure \ref{fig:SuccPlot1} suggests that participants seemed to be pretty eager to add success measures to the success model.
\input{../plots/success.tex}
During the evaluation some participants were not sure which element of the success model was a success model and typed in the name of a factor when trying to make a visualization.
One participant also had the issue that the success modeling service was stuck in the wrong context. Thus they were unfortunately not able to finish this task.
Figure \ref{fig:SuccPlot2} suggests that participants think that success modelling is useful to the community.
\input{../plots/success2.tex}
Overall participants seemed to be eager to add measures to the success model.
We conclude that success modelling does indeed increase the success awareness of the community. 

\subsection{General usability of the bot}
For this section the general usability of the mensabot was evaluated. For this, the System Usability Scale (SUS) was used.
\input{../plots/sus.tex}
Calculating the usability score with the arithmetic means, results in a score of 71,7 which is above the average usability score of 68 and is an adjective rating of \textbf{Good}. 

\subsection{General feedback}
Participants were finally asked to leave general feedback of the chatbot. This section also includes verbal feedback during the evaluation. 

Participants felt that most functionalities were self explanatory. 

%NLU and intent recognition
Participants liked that you could use natural language to communicate with the bot instead of just issuing commands.
They also found it good that the bot could cope with small spelling mistakes.
Participants also noted that the intent recognition was very good.
One participant also noted that they liked that the bot had a "personality". Another participant really liked the Emojis in the bots' responses. A third participant found it helpful that they could always ask the bot for help.

One participant also would have liked to communicate with the bot in German and English

%Mensa
One participant would have preferred to be able to set the default canteen instead of just a default city. 

%Success modelling
Participants found that the success modelling part was not intuitive and would have preferred if the bot could have given more information on this part. 

%Selection handling
Some participants did not like the way users have to select an item for a list. Some found that there were some inconsistencies here as sometimes the bot will expect a number or sometimes the item. 
Participants wished to have a clickable list instead, or buttons where they can select their option.

%Feedback of bot
Participants found it helpful that the bot provides feedback if some operation might take longer, or if something failed. One participant also wrote that "There's a general lack of feedback after commands." We assume that the participant meant the delay between the user input and first response of the bot.  
